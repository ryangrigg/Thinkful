{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf #needed for models in this script\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('html', True) #see the dataframe in a more user friendly manner\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Monte Carlo method is an approach to understanding the results of a random process or group of random processes. The intuition behind a Monte Carlo (MC) simulation is simple, though the implementation can be tricky. Still, the MC approach is well worth understanding, since it's often the simplest way to explore complicated outcomes driven by a series of random events.\n",
    "\n",
    "The MC approach is to model the possible outcomes of a random process using a computer simulation and run that simulation a number of times. The results of these simulations will then give you an understanding of the possible outcomes of the process, often in terms of the distributions of certain outcomes or group of outcomes.\n",
    "\n",
    "To illustrate, let us take the example of flipping a coin. If we wanted to understand the outcome of flipping a coin a number of times, we could calculate out the expectations of the process using some basic probability laws. So, if we flip a coin 10 times, the chance we get four heads is combination(10,4) * .5 or around .21.\n",
    "\n",
    "We could also flip a coin 10 times to see how many times we got heads. We could then repeat this empirical experiment a number of times (since the outcome is random) and see what the probability of four heads converges to.\n",
    "\n",
    "But we can take this an empirical step further and rather than physically flipping the coin, we get a computer to simulate the flipping of a coin. Computers can generate random numbers using a function like those found in the \"random\" library in Python. For example, the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18677976723141387"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "x = random.random()\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "will return a random value (uniformly distributed) between 0 and 1. We can run this code multiple times to get a series of random values for x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844918015476\n",
      "0.908929291537\n",
      "0.48908219359\n",
      "0.493827704763\n",
      "0.944377975415\n",
      "0.527753515578\n",
      "0.0694999326629\n",
      "0.548456283044\n",
      "0.456297087387\n",
      "0.0279335729464\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can then compile the results of this iterative generation of random numbers to get all sorts of measures of the possible outcomes: sums, averages, distributions, and so on.\n",
    "\n",
    "If we wrap the random function in an \"clause\" so that any value above .5 returns a value of \"tail\" (and if not it returns \"head\"), we have essentially simulated the flipping of a coin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tails\n",
      "heads\n",
      "heads\n",
      "heads\n",
      "heads\n",
      "heads\n",
      "tails\n",
      "tails\n",
      "heads\n",
      "heads\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    if random.random() < 0.5:\n",
    "        print 'heads'\n",
    "    else:\n",
    "        print 'tails'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us build on the above example to create a more in-depth simulation.\n",
    "\n",
    "We're going to use the opportunity to demonstrate an entire Python module and a simple class of object. Objects combine data with functionality. They are most appropriate when you have multiple objects that may have relationships with each other. Thus, for simple coins this is a little bit of overkill, but hopefully this will be helpful in understanding objects.\n",
    "\n",
    "You can call this file flipcoins.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529\n",
      "505\n",
      "479\n",
      "495\n",
      "525\n",
      "507\n",
      "513\n",
      "515\n",
      "531\n",
      "511\n"
     ]
    }
   ],
   "source": [
    "'''This script demonstrates simulations of coin flipping'''\n",
    "import random\n",
    "\n",
    "# let's create a fair coin object that can be flipped:\n",
    "\n",
    "class Coin(object):\n",
    "    '''this is a simple fair coin, can be pseudorandomly flipped'''\n",
    "    sides = ('heads', 'tails')\n",
    "    last_result = None\n",
    "\n",
    "    def flip(self):\n",
    "        '''call coin.flip() to flip the coin and record it as the last result'''\n",
    "        self.last_result = result = random.choice(self.sides)\n",
    "        return result\n",
    "\n",
    "# let's create some auxilliary functions to manipulate the coins:\n",
    "\n",
    "def create_coins(number):\n",
    "    '''create a list of a number of coin objects'''\n",
    "    return [Coin() for _ in xrange(number)]\n",
    "\n",
    "def flip_coins(coins):\n",
    "    '''side effect function, modifies object in place, returns None'''\n",
    "    for coin in coins:\n",
    "        coin.flip()\n",
    "\n",
    "def count_heads(flipped_coins):\n",
    "    return sum(coin.last_result == 'heads' for coin in flipped_coins)\n",
    "\n",
    "def count_tails(flipped_coins):\n",
    "    return sum(coin.last_result == 'tails' for coin in flipped_coins)\n",
    "\n",
    "\n",
    "def main():\n",
    "    coins = create_coins(1000)\n",
    "    for i in xrange(10):\n",
    "        flip_coins(coins)\n",
    "        print(count_heads(coins))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "When we run the script, the module's __name__ will be the __main__ module, and so the main() function will be called. The main function will create 1000 simulated coins. It will then simulate flipping them all 100 times, and then print out the number of them that came up heads. Intuitively, this is a way to get a sense for the range and consistency of possible outcomes if in real life you had to flip a fair coin 100 times (or 100 coins).\n",
    "\n",
    "What you'll see is that the result is a sum of random variables. The sum of random variables is a normal random variable. That is, the probability space of outcomes will be shaped like a bell curve. If we created a histogram of these outcomes, that is what we'd likely see.\n",
    "\n",
    "This method can be used to simulate everything from flipping coins and rolling roulette wheels to the performance of portfolios over time.\n",
    "\n",
    "<b>Challenge</b>\n",
    "\n",
    "* Modify the above program to generate trials of a normal variable. How does this distribution look different than the coin-flipping example? What should it look like?\n",
    "* Modify the above program to track the maximum and minimum of each trial of normal variables. Run 100 simulations of these trials. What does the distribution extremes look like? What should it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "******************** TO COMPLETE ***********************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Introduction to Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Artificial neural networks (ANN) are a fascinating attempt to use the model of the human brain to categorize data. The human brain is made up of nerve cells called neurons that attach to other neurons through fiber strands called axons. Axons connect to dendrites, another fiber strand, that also connects to the neuron body. The point at which the axons and dendrities contact is the synpase. Learning in a neurological sense happens as the strength of these synaptic connections between neurons are altered for the same input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an artificial neural network, this structure is replicated with nodes and directed links. The most basic implementation is a perceptron, which has a layer of input nodes and an output node. The input nodes respond to the input and \"signal\" the output node. Each input node is the value of a particular attribute in the dataset. If the attribute is categorical, then there is a node for each possible category with the node sending input only if the category is present.\n",
    "\n",
    "The links between the input node and the output node carry a weight (modeling the strength of a synaptic connection), which the output node uses to properly sum the inputs and arrive at a value. The response generated by the output node is based on this value but conditioned by an activation function that determines the response of the output node.\n",
    "\n",
    "A perceptron learns by reweighting the links between the input layer and the output layer, tuning the response to achieve the desired outcome. Where all links in the perceptron start out with the same weight, as the model learns, those weights change so the activation of different input nodes will result in a different value than was previously the case.\n",
    "\n",
    "This is done with each training instance and only for that instance, so it's easy to \"unlearn\" the training from a previous training iteration if the new instance is contradictory. The learning rate parameter or training threshold is used to limit training adjustments. For problems that are linearly separable (think about the Iris classification problem), the results of a perceptron are guaranteed to converge to the optimal solution, unlike problems that aren't linearly separable, in which case the perceptron won't converge on the optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better replicate the neurological structure of the brain and accomplish classification tasks that aren't linearly separable, the multilayer ANN was developed. As the name suggests, there are additional layers between the input and output layer, called hidden layers, that connect to both input nodes and the output node. In a simple feed-forward arrangement, the nodes in one layer are only connected to the nodes in the next layer so the signal travels directly from input to output. In a recurrent network, nodes can be connected to each other within a layer and to inputs in a previous layer. In this way, a more dynamic relationship between inputs and outputs can be modeled.\n",
    "\n",
    "To train a multilayer ANN, a technique known as back-propagation is used to not only set the weights from the input to the output (as is done in the feed-forward design), but also from the output backward to the input layer. This is a much more complex process and involves estimating the relative cost at each layer and adjusting the weights accordingly to get the desired output, but the result is a function that is a universal apporximator, meaning it can learn any target function. Where previous classifiers you learned about (decision trees, logistic regression, etc.) had difficulty learning more complex decision boundaries (like a curved line), the multilayer ANN can learn these functions and classify data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Activation Function and Self-Driving Cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the most basic implemenation of the activiation function, the response is based simply on the sign of the resulting summed input (+ or -), resulting in a +1 or a -1 as output based on the range of possible values calculated from the input nodes and weights. The activation function can also be a more complex function depending on the desired behavior of the output.\n",
    "\n",
    "For example, one of the applications of ANNs is in self-driving cars. A forward-looking camera records the road and an ANN model runs on the image, with input nodes monitoring various parts of the image. The model detects the center of the lane and keeps the vehicle in its lane by taking the input from the nodes. As the vehicle begins to move out of the lane, the input nodes detect this based on the changing values in their particular area of the image and communicate to the output node, with greater weight given to nodes close to the center than the edge (if the nodes in the center \"see\" the shoulder, the vehicle is really off track).\n",
    "\n",
    "For minimal values of drift from the midline, only a small amount of steering input is required to bring the vehicle back into the lane, but for large values of drift from the midline (the vehicle is going into the opposite lane or off to the shoulder), more drastic steering input is required to bring the vehicle back into the lane. In this case, the activiation function is tuned to the desired response based on the summed value (more steering input based on greater distance from the center of the lane).\n",
    "\n",
    "You can see this process in an early video showing an autonomous navigation system using a simple three-layer ANN. Take a look at this video to see how an ANN is trained. Note the mutliple models being used as an ensemble, with the most confident network being used for a given situation.\n",
    "\n",
    "<b>Challenge:</b>\n",
    "\n",
    "Go back through one of the classification assignments and implement a perceptron and multilayer ANN. How does this compare with what you got with the model you initially developed? Based on what you know, would ANN be a good model to use on this data? Why or why not? This exercise is for your own enrichment so enjoy, but don't feel like you have to spend much time on the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a listing of machine learning packages in Python including refernces to packages for building neural networks: https://wiki.python.org/moin/PythonForArtificialIntelligence#Neural_Networks\n",
    "\n",
    "Good Video to watch on where to go next: https://www.youtube.com/watch?v=GXjjMSn2Nws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
